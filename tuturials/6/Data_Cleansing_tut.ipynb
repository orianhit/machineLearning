{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleansing Tutorial\n",
    "Data Cleansing is one of the steps in preparing the data for predictive model training.<br/>\n",
    "We assume we have performed 'data acquisition' and we want to take that data and process it before starting training.<br/>\n",
    "\n",
    "`Data cleansing`, or `data cleaning`, is the process of detecting and correcting (or removing) mainly corrupt or inaccurate data from a dataset.\n",
    "\n",
    "<u>In this notebook we will cover the the go over the following steps</u>:<br/>\n",
    "* Missing Data\n",
    "* Outliers\n",
    "* Duplicates\n",
    "\n",
    "We will also show some relevant visualizations assisting us in this step.\n",
    "\n",
    "Development: Lahav Yeffet, Moshe Friedman, Valery Brodsky"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages and load our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# for visulaization:\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# some jupyter/ipython magic:\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# show several prints in one cell.\n",
    "# This will allow us to condence every trick in one cell.\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Read Data from CSV file\n",
    "csv_file_name='.' + os.sep + 'data' + os.sep + 'titanic.csv'\n",
    "df = pd.read_csv(csv_file_name, header=0, sep=',') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Investigation of the data in dataframe\n",
    "* Columns\n",
    "* Shape\n",
    "* Data types\n",
    "* some descriptive statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can present some data and get more information from the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### View descriptive statistics. \n",
    "We could later use this also for our data cleansing.<br/>\n",
    "The `describe()` dataframe method provides some useful descriptive information about our features/variables.<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For Numeric values:\n",
    "Descriptive statistics:  min, max, percentile, mean, std etc for numeric values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include=np.number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For non-numeric values:\n",
    "describe() will return different characteristics for non-numeric values, such as number of unique elements, and the most frequent element:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(exclude=np.number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing data\n",
    "We will review the following:\n",
    "* Detect missing values\n",
    "* Remove missing values\n",
    "* Replace missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Detect Missing values\n",
    "- Lets start by finding the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Cabin.head().isnull()  \n",
    "# df.Cabin.head().isna()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could count the number of missing values per feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Cabin.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could also use the dataframe's `info()` method which counts the number of non-missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove Missing values\n",
    " - delete rows or columns with missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the first 8 rows.\n",
    "# use copy() to prevent impact on existing data\n",
    "df2 = df.iloc[:8].copy()\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove rows with missing data\n",
    "df2.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove columns with missing data\n",
    "df2.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove rows only if ALL values are missing\n",
    "df2.dropna(axis=0, how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove rows where not NA is less than \"thresh\" parameter\n",
    "df2.dropna(axis=0, thresh=11).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove columns where not NA is less than \"thresh\" parameter\n",
    "df2.dropna(axis=1, thresh=5).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_clean = df2.dropna(axis=0, thresh=11).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.dropna(axis=0, thresh=11)\n",
    "# we can achieve the same with df2.dropna(axis=0, thresh=11, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replace  missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many mising values?\n",
    "df2 = df.iloc[:8].copy()\n",
    "df2.Age.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Replace with default value\n",
    "In the above example we have only one missing value.<br/>\n",
    "In some cases, we might replace the value with some default value (0 in this case)<br/>\n",
    "* Note: we might do this for both numeric and categorical values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_age = df2.Age.fillna(0)\n",
    "new_age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using the describe dataframe method\n",
    "Displaying analysis on all feature types (for more describe options and explanations, see above). <br/>\n",
    "We could use the output of describe, as explained ahead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Replace with a center metric\n",
    "For numeric values, we might want to replace the values with a metric representing the center of the data.<br/>\n",
    "This could be the mean (arithmetic average) or median for instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_age = df2.Age.fillna(df2.Age.mean())\n",
    "new_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.Age = df2.Age.fillna(df2.Age.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.fillna(df2.median(), inplace=True)\n",
    "df2.info() # info shows there are no more missing values for age:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Replace with the most frequent value\n",
    "For categorical values, we might want to replace the values with the most frequent values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Embarked.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Embarked\"].fillna('S',inplace=True)\n",
    "#df.Embarked = df.Embarked.fillna(df.Embarked.mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.iloc[:8].copy()\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill values forward, i.e. propagate last known observation until the next valid. \n",
    "df2.fillna(method = 'ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill values backforward, i.e. use next valid observation to fill the gap\n",
    "df2.fillna(method = 'bfill')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "1. Print how many missing values in the column \"**Age**\" for **df** \n",
    "2. Copy 20 first rows\n",
    "3. Drop columns with missing data\n",
    "4. Drop Rows with missing data\n",
    "5. Fill Missing values for the column **Age** with the average value of the column\n",
    "6. Fill missing values for all colums using **ffill** method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR SOLUTION HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outliers\n",
    "We will refer only to extreme values as outliers in our scope here.<br/>\n",
    "We will also refer only to outliers in the feature level.<br/>\n",
    "\n",
    "The following will describe:\n",
    "* Understanding our data to help with outlier detection\n",
    "* Detecting outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_name='.' + os.sep + 'data' + os.sep + 'titanic.csv'\n",
    "df = pd.read_csv(csv_file_name, header=0, sep=',') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Understanding our data to help with outlier detection\n",
    "Using descriptive statistics and visualization to see how the data looks like"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Descriptive statistics\n",
    "let's use describe to see how the data looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualizing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Visualizing the data with Histograms\n",
    "Use histogram to analyze data and find outliers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df.Fare, bins=50)\n",
    "plt.xlabel=(\"Fare\")\n",
    "plt.ylabel=(\"Frequency\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(df.Fare>200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Visualizing the data with Boxplots\n",
    "\n",
    "A **boxplot** is a standardized way of displaying the distribution of data based on a five number summary (“minimum”, first quartile (Q1), median, third quartile (Q3), and “maximum”).\n",
    "\n",
    "\"mimimum\" = Q1 - 1.5 * IQR\n",
    "\n",
    "\"maximum\" = Q3 + 1.5 * IQR\n",
    "\n",
    "IQR: interquartile Range\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(df.Age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Age.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Detecting outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Detecting outliers Find Outliers using quartiles and IQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find outliers for Fare column using quartiles\n",
    "\n",
    "Q1 = np.percentile(df[\"Fare\"], 25)\n",
    "Q3 = np.percentile(df[\"Fare\"], 75)\n",
    "IQR = Q3 - Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fare_outlier_rows = df[(df[\"Fare\"] < Q1 - 1.5*IQR) | (df[\"Fare\"] > Q3 + 1.5*IQR )].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Fare_outlier_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find outliers for multiple columns based on quartiles\n",
    "mycols = [\"Age\",\"Fare\"]\n",
    "all_outlier_rows = []\n",
    "for col in mycols:        \n",
    "        Q1 = np.percentile(df[col], 25)\n",
    "        Q3 = np.percentile(df[col], 75)\n",
    "        IQR = Q3 - Q1\n",
    "        IQR_range = 1.5 * IQR\n",
    "        col_outlier = df[(df[col] < Q1 - IQR_range) | \n",
    "                              (df[col] > Q3 + IQR_range )].index\n",
    "        all_outlier_rows.extend(col_outlier)\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_outlier_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do we have rows appearing twice in the list?\n",
    "len(set(all_outlier_rows))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Detecting Outliers using t-score\n",
    "t scores with high absolute value, have a high chance to be an outliers, assuming the data tends to normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_score = (df[\"Fare\"] - df[\"Fare\"].mean()) / df[\"Fare\"].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t-score > 3 or <-3 has a high chance to be an outlier\n",
    "outliers = abs(t_score) > 3\n",
    "sum(outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove Outliers from the data\n",
    "We could use a similar approach for detected outliers.<br/>\n",
    "Many times we just decide to remove the extreme values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "min(df.Fare[outliers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Fare[df.Fare>200] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Fare\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_name='.' + os.sep + 'data' + os.sep + 'titanic.csv'\n",
    "df = pd.read_csv(csv_file_name, header=0, sep=',') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = np.percentile(df[\"Fare\"], 25)\n",
    "Q3 = np.percentile(df[\"Fare\"], 75)\n",
    "IQR = Q3 - Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Fare[(df[\"Fare\"] < Q1 - 1.5*IQR) | (df[\"Fare\"] > Q3 + 1.5*IQR )] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Fare.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_name='.' + os.sep + 'data' + os.sep + 'titanic.csv'\n",
    "df = pd.read_csv(csv_file_name, header=0, sep=',') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_score = (df[\"Fare\"] - df[\"Fare\"].mean()) / df[\"Fare\"].std()\n",
    "outliers = abs(z_score) > 3\n",
    "sum(outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Fare[outliers] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Exercise 2\n",
    "\n",
    "1. Read data/titanic.csv and plot an histogram for the **age** column with 10 bins\n",
    "2. Create a **boxplot** for the **Fare** column. How many outliers?\n",
    "3. Drop nas and Calculate the Interquartile range for the **Age** column\n",
    "4. Print how many outliers exists for the **Age** column using **zcore > 2.5** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### YOUR SOLUTION ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duplications\n",
    "In this section we will review:\n",
    "* duplication detection\n",
    "* duplication handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "csv_file_name='.' + os.sep + 'data' + os.sep + 'titanic.csv'\n",
    "df = pd.read_csv(csv_file_name, header=0, sep=',') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_name2='.' + os.sep + 'data' + os.sep + 'titanic_small.csv'\n",
    "df2 = pd.read_csv(csv_file_name2, header=0, sep=',') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Duplication detection\n",
    "DataFrrame **duplicated()** method returns boolean Series of duplicated rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.duplicated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df2[df2.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use duplicated() to find duplicates for column \n",
    "df[df.duplicated(['Name'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.duplicated(['Name'])].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display rows with duplicates in  'Name' column\n",
    "df2[df2.duplicated(['Name'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Embarked.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Embarked.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Duplication handling\n",
    "In some cases we might want to remove the duplications.<br/>\n",
    "This should be done with caution and not be used at all cases.<br/>\n",
    "If we are sure the duplication refers to the same data (and not only the same feature vector values), we probably will want to remove the duplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicated data from the dataframe\n",
    "df2.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_name2='.' + os.sep + 'data' + os.sep + 'titanic_small.csv'\n",
    "df2 = pd.read_csv(csv_file_name2, header=0, sep=',') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.drop_duplicates(subset=['Sex'])\n",
    "# We can also use keep='last' if we want to save the last copy of each duplication group "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "\n",
    "1. Print how many duplicates for the *Age* column in **df**\n",
    "2. Print the unique values of the **Sex** column \n",
    "3. drop duplicates of df2 according to the **Embarked** column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR SOLUTION ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
